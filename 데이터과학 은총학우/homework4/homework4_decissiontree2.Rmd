---
title: "homework4"
author: "eunchong"
date: '2019 7 3 '
output: html_document
---

#1 
: decision tree를 사용해서 income 변수를 가장 잘 예측하는 예측 모델을 만드시오. 어떻게 그 모델을 찾게 되었는지 설명하시오.        confusion matrix, accuracy, precision, recall을 사용해 만든 모델의 성능을 설명하시오


```{r}
# get_arruracy 
get_acuuracy <- function(pred, actual){
  tble <- table(actual, pred)
  return( (tble[1,1]+tble[2,2])/sum(tble))
}



# get_precision


get_precision <- function(pred, actual){
  tble <- table(actual, pred)
  return( (tble[2,2])/ sum(tble[1,2],tble[2,2]))
}



#get_recall
get_recall <- function(pred, actual){
  tble <- table(actual, pred)
  return( tble[2,2]/ sum(tble[2,1],tble[2,2]))
}
```


## 모델1
```{r setup, include=FALSE}
load("C:/Users/21500/Desktop/homework/homework4/income_hw4.RData")
str(train)

############
library(rpart)
library(rpart.plot)

new.train <- train

train_model.train.full <- rpart(income~ . , data = new.train, method = "class",
                    control = rpart.control(cp = 0)) 

plotcp(train_model.train.full) #0.0014 = cp 

##Prune the tree
train_model_pruned <- prune(train_model.train.full, cp = 0.0014)
train_model_pruned


# train set
new.train$pred <- predict(train_model.train.full, new.train, type = "class")

#table
table(new.train$income , new.train$pred)

mean(new.train$income == new.train$pred) # 0.888
get_precision(new.train$pred, new.train$income) # precision : 0.814
get_recall(new.train$pred, new.train$income)    # recall : 0.713

rpart.plot(train_model_pruned)

```


## 모델 2
```{r cars}

new.train2 <- train

train_model.full <- rpart(income~ . , data = new.train2, method = "class",
                    control = rpart.control(cp = 0)) 

plotcp(train_model.full) #0.0072 = cp 

##Prune the tree
train_model_pruned2 <- prune(train_model.full, cp = 0.0072)
train_model_pruned2

#table
table(new.train2$income , new.train2$pred)

# train set
new.train2$pred <- predict(train_model_pruned2, new.train2, type = "class")

mean(new.train2$income == new.train2$pred) # accuracy : 0.848
get_precision(new.train2$pred, new.train2$income) # precision : 0.726
get_recall(new.train2$pred, new.train2$income)    # recall : 0.627


new.test <- test
new.test$pred <- predict(train_model_pruned2, new.test, type = "class")

mean(new.test$income == new.test$pred) # accuracy : 0.847
get_precision(new.test$pred, new.test$income) # precision : 0.718
get_recall(new.test$pred, new.test$income)    # recall : 0.636

```
0.726

## 모델 3
```{r pressure, echo=FALSE}
new.train3 <- train


train_model3 <- rpart(income~ . , data = new.train3, method = "class", control= rpart.control(cp = 0, minsplit = 300)) 



# train set
new.train3$pred <- predict(train_model3, new.train3, type = "class")

#table
table(new.train3$income , new.train3$pred)

mean(new.train3$income == new.train3$pred) # accuracy : 0.855
get_precision(new.train3$pred, new.train3$income) # precision : 0.779
get_recall(new.train3$pred, new.train3$income)    # recall : 0.586


```

## 모델 4
```{r}
new.train4 <- train


train_model4 <- rpart(income~ . , data = new.train4, method = "class", control= rpart.control(cp = 0, minsplit = 250)) 

# train set
new.train4$pred <- predict(train_model4, new.train4, type = "class")

#table
table(new.train4$income , new.train4$pred)

mean(new.train4$income == new.train4$pred) # accuracy : 0.858
get_precision(new.train4$pred, new.train4$income) # precision : 0.752
get_recall(new.train4$pred, new.train4$income)    # recall : 0.639
```


## 모델 5
```{r}
new.train5 <- train


train_model5 <- rpart(income~ . , data = new.train5, method = "class", control= rpart.control(cp = 0, minsplit = 200)) 



# train set
new.train5$pred <- predict(train_model5, new.train5, type = "class")

#table
table(new.train5$income , new.train5$pred)

mean(new.train5$income == new.train5$pred) # accuracy : 0.858
get_precision(new.train5$pred, new.train5$income) # precision : 0.761
get_recall(new.train5$pred, new.train5$income)    # recall : 0.629
```
## 모델 6
```{r}
new.train6 <- train


train_model6 <- rpart(income~ . , data = new.train6, method = "class", control= rpart.control(cp = 0, minsplit = 100)) 


# train set
new.train6$pred <- predict(train_model6, new.train6, type = "class")

#table
table(new.train6$income , new.train6$pred)

mean(new.train6$income == new.train6$pred)        # accuracy : 0.863
get_precision(new.train6$pred, new.train6$income) # precision : 0.775
get_recall(new.train6$pred, new.train6$income)    # recall : 0.633
```

## 모델 7
```{r}
new.train7 <- train


train_model7 <- rpart(income~ . , data = new.train7, method = "class", control= rpart.control(cp = 0, minsplit = 50)) 

# train set
new.train7$pred <- predict(train_model7, new.train7, type = "class")

#table
table(new.train7$income , new.train7$pred)

mean(new.train7$income == new.train7$pred)        # accuracy : 0.871
get_precision(new.train7$pred, new.train7$income) # precision : 0.797
get_recall(new.train7$pred, new.train7$income)    # recall : 0.649
```
## 모델 7
```{r}
new.train7 <- train


train_model7 <- rpart(income~ . , data = new.train7, method = "class", control= rpart.control(cp = 0, minsplit = 30)) 

# train set
new.train7$pred <- predict(train_model7, new.train7, type = "class")


#table
table(new.train7$income , new.train7$pred)

mean(new.train7$income == new.train7$pred) # accuracy : 0.88
get_precision(new.train7$pred, new.train7$income) # precision : 0.806
get_recall(new.train7$pred, new.train7$income)    # recall : 0.681



```

## 모델 8
```{r}
new.train8 <- train


train_model8 <- rpart(income~ . , data = new.train8, method = "class", control= rpart.control(cp = 0, minsplit = 10)) 



# train set
new.train8$pred <- predict(train_model8, new.train8, type = "class")

#table
table(new.train8$income , new.train8$pred)

mean(new.train8$income == new.train8$pred) # accuracy : 0.912
get_precision(new.train8$pred, new.train8$income) # precision : 0.857
get_recall(new.train8$pred, new.train8$income)    # recall : 0.776

rpart.plot(train_model8)


new.test2 <- test


#### test ####
new.test <- test
new.test$pred <- predict(train_model8 , new.test, type = "class")

mean(new.test$income == new.test$pred) # accuracy : 85.15 / 83.4
get_precision(new.test$pred, new.test$income) # precision : 83.0% / 67.9
get_recall(new.test$pred, new.test$income)    # recall :  74.0% / 63.1


```


#2 의사결정나무 그리기
```{r}
library(rpart.plot)

rpart.plot(train_model8)
```


가장 성능은 좋지만 너무 많은 node(decision, leaf)가 있기 때문에 의사 결정에 도움이 되지 않는 모델이 되었다.

따라서 만든 모델 중 적절한 node가 있으면서 성능이 높은 모델을 다시 선택하여 그림을 그려보고자 한다. 

앞서 가정했듯이 소득이 50만불 이상인 사람에게 메일을 보내서 성금을 많이 모으려는 목적이기 때문에 precision보다 recall 값에 더 초점을 맞추고자 한다.

```{r}
new.train9 <- train


train_model9 <- rpart(income~ . , data = new.train9, method = "class", control= rpart.control(cp = 0, maxdepth = 4)) 



# train set
new.train9$pred <- predict(train_model9, new.train9, type = "class")

#table
table(new.train9$income , new.train9$pred)

mean(new.train9$income == new.train9$pred)        # accuracy : 0.84
get_precision(new.train9$pred, new.train9$income) # precision : 0.772
get_recall(new.train9$pred, new.train9$income)    # recall : 0.509

par(cex = 1.5)
rpart.plot(train_model9)


```



#3 overfitting

##1 test set에서 확인하기 
```{r}

new.test <- test
new.test$pred <- predict(train_model9 , new.test, type = "class")

mean(new.test$income == new.test$pred)        # accuracy : 0.842
get_precision(new.test$pred, new.test$income) # precision : 0.769
get_recall(new.test$pred, new.test$income)    # recall : 0.522



```
train set보다 오히려 test set에서 전반적으로 모두 더 높은 성능을 가진다. 


##2 교차 

```{r}
set.seed(2019)
n.income <- nrow(test)
rgroup <- runif(n.income)

# test1, test2
test.df1 <- subset(test, rgroup <= 0.6) 
test.df2  <- subset(test, rgroup >  0.6)

# test1
new.test.df1 <- test.df1

new.test.df1$pred <- predict(train_model9 , new.test.df1, type = "class")

mean(new.test.df1$income == new.test.df1$pred) # accuracy : 0.839
get_precision(new.test.df1$pred, new.test.df1$income) # precision : 0.757
get_recall(new.test.df1$pred, new.test.df1$income)    # recall : 0.514



# test2
new.test.df2 <- test.df2

new.test.df2$pred <- predict(train_model9 , new.test.df2, type = "class")

mean(new.test.df2$income == new.test.df2$pred) # accuracy : 0.847
get_precision(new.test.df2$pred, new.test.df2$income) # precision : 0.787
get_recall(new.test.df2$pred, new.test.df2$income)    # recall : 0.535


```
test셋을 다시 test1, test2 로 나눠서 성능을 측정한 결과 train data의 성능과 유사하다. 따라서 과적합이 아니라는 판단이 든다.


##################################################################

#2 KNN

## Question 4
```{r}
load("C:/Users/21500/Desktop/homework/homework4/income_hw4.RData")


train.knn <- train
test.knn <- test


# one hot encoding
library(dummies)

train.knn <- dummy.data.frame(train.knn)
test.knn <-dummy.data.frame(test.knn)

str(train.knn)

# min-max normalization
minmax_norm <- function(x) {
(x-min(x))/(max(x)-min(x))
}

train.knn$age <- minmax_norm(train.knn$age)
train.knn$capital.gain <- minmax_norm(train.knn$capital.gain)
train.knn$capital.loss <- minmax_norm(train.knn$capital.loss)
train.knn$hours.per.week <- minmax_norm(train.knn$hours.per.week) 
train.knn$education.num <- minmax_norm(train.knn$education.num)
train.knn$income <- as.factor(train.knn$income)
train.knn$income <- ifelse(train.knn$income =="1", "rich", "poor")

test.knn$age <- minmax_norm(test.knn$age)
test.knn$capital.gain <- minmax_norm(test.knn$capital.gain)
test.knn$capital.loss <- minmax_norm(test.knn$capital.loss)
test.knn$hours.per.week <- minmax_norm(test.knn$hours.per.week) 
test.knn$education.num <- minmax_norm(test.knn$education.num) 
test.knn$income <- as.factor(test.knn$income)
test.knn$income <- ifelse(test.knn$income =="1", "rich", "poor")

# split data into train and test set 
dim(train.knn)

train.knn_new <- train.knn[, -47]  
test.knn_new <-  test.knn[, -47]

train.knn_label <- train.knn[, 47]  
test.knn_label <-  test.knn[, 47]



# choosing proper k 
sqrt(nrow(train.knn)) # 146.639

library(class)

train.knn_pred <-  knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = 147)

#accuracy
mean(test.knn_label == train.knn_pred) # 0.827

 
#confusion matrix
cmat <- table(test.knn_label, train.knn_pred)  # 실제, 예측
cmat

#precision
cmat[2,2] / sum(cmat[,2]) # 0.687

#recall
cmat[2,2] / sum(cmat[2,]) # 0.56

############################################

test.knn_pred_P <- knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = 147, prob = TRUE)
head(attributes(test.knn_pred_P)$prob,10)


#음성이라면 그대로 확률을 쓸 것이고, 양성이라면 1-prob을 할 것이다 
# converting all Prob to P(rich)

test_pred_prob <- ifelse(test.knn_pred_P == 'rich', 
attributes(test.knn_pred_P)$prob,
1-attributes(test.knn_pred_P)$prob)

head(test_pred_prob)



# AUC for our kNN
library(ROCR)
library(Epi)

ROC(test_pred_prob, test.knn_label== 'rich') # 0.883



##### set lower threshold #####
threshold <- 0.3
test_pred_new <- ifelse(test_pred_prob > threshold, 'rich', 'poor')

# matrix
cmat <- table(test.knn_label, test_pred_new) 
cmat

#accuracy
mean(test.knn_label == test_pred_new) # 0.801

#precision
cmat[2,2] / sum(cmat[,2]) # 0.571

#recall
cmat[2,2] / sum(cmat[2,]) # 0.8



```


## Question 5 : 다양한 k를 시도해보고 가장 성능이 좋은 k를 찾아보시오. 
k를 변화하면서 accuracy, precision, recall, AUC가 변화하는 것을 보기 위해 그래프를 그리시오. 
```{r}

k_value <- c(10, 30, 50, 70, 90, 110, 130, 147, 170, 200)

# accuracy 
knn_accuracy <- function(k_value){
  test.knn_pred_P <- knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = k_value, prob = TRUE)
  test_pred_prob <- ifelse(test.knn_pred_P == 'rich', attributes(test.knn_pred_P)$prob,1-attributes(test.knn_pred_P)$prob)
  test_pred_new <- ifelse(test_pred_prob > 0.3, 'rich', 'poor')
  a <- mean(test.knn_label == test_pred_new) 
  return(a)
}

# precision
knn_precision <- function(k_value){
  test.knn_pred_P <- knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = k_value, prob = TRUE)
  test_pred_prob <- ifelse(test.knn_pred_P == 'rich', attributes(test.knn_pred_P)$prob,1-attributes(test.knn_pred_P)$prob)
  test_pred_new <- ifelse(test_pred_prob > 0.3, 'rich', 'poor')
  cmat <- table(test.knn_label, test_pred_new)
  a <- cmat[2,2] / sum(cmat[,2])
  return(a)
}

# recall
knn_recall <- function(k_value){
  test.knn_pred_P <- knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = k_value, prob = TRUE)
  test_pred_prob <- ifelse(test.knn_pred_P == 'rich', attributes(test.knn_pred_P)$prob,1-attributes(test.knn_pred_P)$prob)
  test_pred_new <- ifelse(test_pred_prob > 0.3, 'rich', 'poor')
  cmat <- table(test.knn_label, test_pred_new)
  a <- cmat[2,2] / sum(cmat[2,])
  return(a)
}
# AUC

calAUC <- function(predCol, targetCol){
perf <- performance(prediction(predCol, targetCol), 'auc') 
as.numeric(perf@y.values)
}


knn_AUC <- function(k_value){
  test.knn_pred_P <- knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = k_value, prob = TRUE)
  test_pred_prob <- ifelse(test.knn_pred_P == 'rich', attributes(test.knn_pred_P)$prob,1-attributes(test.knn_pred_P)$prob)
  a <- calAUC(test_pred_prob,test.knn_label== 'rich')
}





accuracy2 <- sapply(k_value, knn_accuracy)
precision2 <- sapply(k_value, knn_precision)
recall2 <-    sapply(k_value, knn_recall)
AUC <- sapply(k_value, knn_AUC)




par(mfrow=c(2,2))
plot(k_value, accuracy2, type="o", xlim=c(10,200), col="red", lwd=2, main = "accuracy")
plot(k_value, precision2 ,type="o", xlim=c(10,200),col="blue",lwd=2, main = "precision")
plot(k_value, recall2 ,type="o", xlim=c(10,200),col="orange",lwd=2, main = "recall")
plot(k_value, AUC ,type="o", xlim=c(10,200), col="dark green",lwd=2, main = "AUC")


```

AUC 기준으로 k가 30일때가 가자 성능이 좋다. 

## Question 6 : best K를 사용한 kNN에 대해서 ROC 커브를 그리고 AUC를 계산해보시오.

```{r}
train.knn_pred <-  knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = 30)

#accuracy
mean(test.knn_label == train.knn_pred) # 0.835

 

############################################

test.knn_pred_P <- knn(train = train.knn_new , test = test.knn_new , cl = train.knn_label, k = 30, prob = TRUE)


#음성이라면 그대로 확률을 쓸 것이고, 양성이라면 1-prob을 할 것이다 
# converting all Prob to P(rich)

test_pred_prob <- ifelse(test.knn_pred_P == 'rich', 
attributes(test.knn_pred_P)$prob,
1-attributes(test.knn_pred_P)$prob)



# AUC for our kNN
library(ROCR)
library(Epi)

ROC(test_pred_prob, test.knn_label== 'rich') # 0.885 



```

# Question 7. 
데이터에 kNN을 적용하기 위해서 데이터를 어떻게 변형하였나요? 이유와 방법을 설명하시오.

knn은 입력변수가 numeric 이어야 하므로 factor 형식인 workclass, marital.status occupation ,relationship, race, sex 변수를 dummies library를 사용해서 더미변수로 바꿔주었다.

또한 변수마다 값의 범위와 스케일이 다르기 떄문에 정규화를 통해 거리의 차이를 비슷하게 맞춰줘야 한다.
따라서 age, capital.gain ,capital.loss ,hours.per.week, education.num 를 정규화 시켰다.

또한 목적변수인 income변수를 factor로 바꾸고 0이면 poor, 1이면 rich로 바꿔주었다. 

# Question 8.

해당 데이터 셋에서 decision tree, kNN 두가지 모델을 비교했을 때 어떤 것이 성능이 더 좋은가요? 그 이유는 무엇이라고 생각하나요?


mean(new.test.df2$income == new.test.df2$pred)        # accuracy : 0.847
get_precision(new.test.df2$pred, new.test.df2$income) # precision : 0.787
get_recall(new.test.df2$pred, new.test.df2$income)    # recall : 0.535


ROC(test_pred_prob, test.knn_label== 'rich')  # AUC : 0.885 
mean(test.knn_label == test_pred_new)         # accuracy : 0.801
cmat[2,2] / sum(cmat[,2])                     # precision : 0.571
cmat[2,2] / sum(cmat[2,])                     # recall : 0.8


KNN의 성능이 더 우수하다.

1) 의사결정나무에서는 연속형 변수를 이산형 값으로 분리해서 취급하기 때문에, 분리의 경계점 근방에서는 예측 오류가 클 가능성이 있기 때문이다. 
2) depth를 늘릴수록 수치적으로는 성능이 좋아지지만, 트리가 복잡해지는 문제가 발생하기 때문이다. 

# Question 9. 모델 비교 


