---
title: "Final Exam Report"
output: html_document
---

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(caret)
library(ROCR)
library(rpart)
library(class)
library(leaps)
library(kknn)
library(MASS)
library(earth)
library(randomForest)
```

```{r}
load("C:/Users/sec/Desktop/교과목들/데이터 과학/final_test.RData")
```

```{r}
balanced_accuracy <- function(tb){
  sensitivity <- sum(tb[1,1])/sum(tb[,1])
  specificity <- sum(tb[2,2])/sum(tb[,2])
  return((sensitivity+specificity)/2)
  
}

```

```{r}
calcRMSE <- function(label, estimation){
  return(sqrt(mean((label-estimation)**2)))
}
```

# Question1

여러 전처리를 수행할 데이터 프레임을 지정
```{r}
shopping_trains <- shopping_train
shopping_tests <- shopping_test
```

classification의 여러 방법중 다변량 적응 회귀 스플라인(MARS) 의 방법을 사용했습니다.

이는 linear와 마찬가지로 변수 간의 상호작용항을 지원하며 데이터의 전처리과정이 거의 필요없는 유의성을 갖습니다. 


earth()함수를 이용하여 데이터의 어떤 것도 건들지 않는 상태에서 기본 모형을 우선 돌렸습니다.

교차 검증을 기본으로 수행하며 5겹 교차검증과 이를 3번 반복하였습니다.
```{r}
earth <- earth(Revenue~., data=shopping_train, nfold=5, ncross=3)
```

evimp함수를 통해 유의미한 피처를 뽑으면 다음과 같습니다.
nsubsets는 교차 검증을 하면서 여러 모델들의 부분집합을 의미하고 gcv, rss의 지표가 크면 클수록 더 영향력이 있는 변수입니다.
```{r}
evimp(earth)
```

다변량 적응 회귀 스플라인을 사용한 모델에서는 여러 변수를 추가해보고 type을 변경해서 여러 시도를 했지만 결국 그냥 현 그대로의 데이터를 사용하고 변수간의 여러 상호작용항을 적용시켜 문제를 푼 것이 가장 성능이 좋았었습니다.

이렇게 만든 최종 모델은 다음과 같습니다.

```{r}
earths <- earth(Revenue~Administrative+Administrative_Duration+Informational+Informational_Duration+ProductRelated+ProductRelated_Duration+
                  +BounceRates+ExitRates+SpecialDay+Month+Region*TrafficType+VisitorType+Weekend+Region+
                  PageValues+Administrative*PageValues+
                  Informational*SpecialDay+BounceRates*ExitRates+TrafficType*Region+VisitorType*Region+PageValues*BounceRates+
                  PageValues*ExitRates+Administrative_Duration*PageValues+Month*ExitRates+Administrative*SpecialDay+
                  Administrative_Duration*PageValues+PageValues*ProductRelated+Month*ProductRelated+ProductRelated*Informational+
                  Administrative*ProductRelated
                , data=shopping_trains, nfold=5, ncross=3)
```

우선, 직접 변수를 넣었다 빼면서 여러 성능을 검사한 결과, Operating System이랑 Browser는 특별히 고객의 구매 여부에 영향을 미치지는 않았습니다. 본인의 컴퓨터가 어떤 OS이고 어떤 브라우저를 쓰는 지는 해당 물품을 구매하는 지의 여부와 크게 관련이 없음은 직관과 어느 정도 들어맞습니다.

그 뒤 여러 변수들간의 관계성이 높은 변수들을 중심으로 상호작용을 적용시켜 모델을 적용시켰습니다. 변수간의 상관성을 세밀히 관찰하고 접근을 시도했어야 했는데 시간의 압박에 일일이 하나씩 교차 검증을 시도했던 것 같습니다. 이 부분이 balance accuracy가 상당히 낮은 이유였던 것 같습니다.

이후 추정치의 확률값을 구하고
```{r}
shopping_trains$pred <- predict(earths, newdata=shopping_trains, type='response')
```


```{r}
aggregate(pred~Revenue, data=shopping_trains, mean)
```

대강의 threshold를 구하기 위한 수입 대비 확률을 구해보면 대략 다음과 같이 나옴을 확인할 수 있습니다.

우선 대강 0.4의 threshold로 잡고 접근을 시도했습니다.
```{r}
shopping_trains$pred_logic <- ifelse(shopping_trains$pred > 0.4, TRUE, FALSE)
```

이후 혼동행렬을 구해보면
```{r}
tbs <- table(pred=shopping_trains$pred_logic, actual = shopping_trains$Revenue)
tbs
```

다음과 같이 구성됨을 확인할 수가 있었습니다.

하지만 이 모델의 경우 테스트 서버에서 AUC는 제법 높게 나왔지만

balanced_accuracy가 상당히 낮게 나왔었습니다. 아마 변수의 전처리를 밟지않고 threshold에 대한 세밀한 조정이 있지 않아 나온 결과라고 판단됩니다.

```{r}
balanced_accuracy(tbs)
```

학습 데이터에서 balanced accuracy는 0.82정도로 나왔었습니다.

```{r}
p <- prediction(shopping_trains$pred, shopping_trains$Revenue)
auc <- performance(p, 'auc')
auc@y.values[[1]]
```

반면 AUC는 0.92가 나옴을 확인할 수가 있었습니다.


```{r}
shopping_tests$pred <- predict(earths, newdata=shopping_tests, type='response')
shopping_tests$pred_logic  <- ifelse(shopping_tests$pred >0.4, 1, 0)
prob_shopping_test <- shopping_tests$pred
pred_shopping_test <- shopping_tests$pred_logic
```

이렇게 만들어낸 최종 모델을 적용시켜 서버에 게시하였습니다.

AUC수치랑 balanced accuracy가 어느 정도 큰 것을 보면 overfitting이 어느정도 의심되는 결과가 나와 조금 아쉬운 접근이었습니다.

단순히 로지스틱 선형회귀나 다른 접근으로 갔으면 더 좋았을 것 같은데 시간이 가용했으면 더 이런 저런 시도를 해보았을 것 같은데 이 부분이 상당히 아쉬웠습니다.

또한 변수에 대한 해석과 전처리를 거의 하지 않고 분석을 시도했다는 점도 상당한 한계점으로 작용한 것 같습니다. 시간이 충분히 있었으면 변수를 만지작거리면서 더 다양한 접근을 시도해보았을 텐데 이 부분의 접근이 잘못되었던 것 같습니다.

# Question2

집값을 예측하는 데이터 프레임은 다음과 같습니다.

```{r}
str(housing_train)
```

우선 전처리를 할 데이터 프레임을 만들어주고
```{r}
housing_trains <- housing_train
housing_tests <- housing_test
```

집의 age변수는 group화하여 전처리를 수행해 주었습니다.
```{r}
housing_trains$age_group <- cut(housing_trains$X2, breaks = c(0,8.95,15.60,17.24,26.55,43.80,Inf), lables=c("1","2","3","4","5","6"), right=F)
housing_tests$age_group <- cut(housing_tests$X2, breaks = c(0,8.95,15.60,17.24,26.55,43.80,Inf), lables=c("1","2","3","4","5","6"), right=F)
```

그리고 예측에 방해가 되는 날짜 데이터는 제거하였습니다. 시계열을 적용시켜 하려는 시도를 해보았으나 그다지 현 데이터 프레임에는
의미가 없어 제거하였습니다.

물론 데이터가 충분히 많고 시계열을 적용시키기 적합한 모형도 만들 수 있으나 시간 관계상 우선 생략하는 방향으로 접근을 시도했습니다.
```{r}
housing_trains <- housing_trains[, c(-1)]
housing_tests <- housing_tests[, c(-1)]
```

우선 주변에 있는 편의점의 수를 factorize하여 계산을 수행했을 때, 오히려 더 성능이 떨어지는 결과가 나왔습니다. 이후 다른 변수들의 전처리도 마찬가지였습니다. 고로 이 데이터프레임 또한 age_group의 변수만 추가하여 모델링 구축을 시도하였습니다.

모델의 경우 RandomForest를 사용하였습니다. RandomForest특성상 매번 성능이 바뀌는 단점이 있어 경험적으로 가장 성능이 좋았던 모델을 채택했고 이 경우 ntree는 700개를 만들어 분석을 수행하였고 mtry는 변수의 갯수가 총 7개라 7/3인 대략 2~3개 정도의 mtry를 설정하여 분석을 시도하였습니다. 

```{r}
rf.fit2 <- randomForest(Y~., data=housing_trains, mtry=3, ntree=700, importance=T)
rf.fitts <- predict(rf.fit2, newdata=housing_trains)
rf.tests <- predict(rf.fit2, newdata=housing_tests)
```

```{r}
calcRMSE(rf.fitts, housing_trains$Y)
```

그렇게 구했던 RMSE는 3.37이 나왔고 실제 서버상의 테스트 데이터에서는 9.453이 나왔습니다.

이렇게 최종적으로 분석을 수행한 모델을 서버에 제출하였습니다.

변수에 대한 해석과 충분한 지식이 데이터 분석에 얼마나 중요한 지를 여실히 깨닫는 순간이었습니다. 알고 있는 화려한 통계 지식과 머신러닝 기법보다 결국 의미의 해석과 변수에 대한 깊은 이해가 훨씬 더 중요함을 알게되는 순간이었습니다.

개인적으로 힘들기도 했지만, 정말 재미있었고 많이 배웠던 수업이었습니다!! 한 학기 동안 너무 감사했습니다!! 감사합니다 교수님!!



```{r}
pred_housing_test <- as.vector(rf.tests)
save(prob_shopping_test, pred_shopping_test, pred_housing_test, file="st21600685.RData")
```
